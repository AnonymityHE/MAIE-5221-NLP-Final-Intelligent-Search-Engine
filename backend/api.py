"""
FastAPIè·¯ç”±å®šä¹‰
"""
from typing import Optional, List, Dict
from fastapi import APIRouter, HTTPException, UploadFile, File as FastAPIFile, WebSocket, WebSocketDisconnect
from fastapi.responses import JSONResponse
from backend.models import (
    QueryRequest, QueryResponse, DocumentResult, FileUploadResponse,
    SpeechRequest, SpeechResponse, VoiceQueryRequest, VoiceQueryResponse
)
from services.vector import retriever
from services.llm import llm_client, unified_llm_client, usage_monitor
from services.agent import agent
from services.storage import file_storage, file_processor, file_indexer
from services.core import settings, logger
from services.core.cache import get_cache_stats, clear_cache
import asyncio
import os
import tempfile

router = APIRouter()


@router.post("/rag_query", response_model=QueryResponse)
async def rag_query(request: QueryRequest):
    """
    RAGæŸ¥è¯¢æ¥å£ï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰
    
    æ¥æ”¶ç”¨æˆ·é—®é¢˜ï¼Œä»Milvusæ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼Œä½¿ç”¨LLMç”Ÿæˆç­”æ¡ˆã€‚
    å¦‚æœæ²¡æœ‰æ£€ç´¢åˆ°æ–‡æ¡£ï¼ˆRAGåº“ä¸ºç©ºï¼‰ï¼Œåˆ™ç›´æ¥è°ƒç”¨LLMå›ç­”ã€‚
    
    æ³¨æ„ï¼šå¦‚æœuse_agent=Trueï¼Œä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°Agentæ¨¡å¼ã€‚
    """
    # å¦‚æœè¯·æ±‚ä½¿ç”¨Agentï¼Œé‡å®šå‘åˆ°Agentæ¥å£
    if request.use_agent:
        return await agent_query(request)
    try:
        # 1. ä»Milvusæ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼ˆåŒ…æ‹¬ä¸Šä¼ çš„æ–‡ä»¶ï¼‰
        search_results = retriever.search(request.query, request.top_k)
        
        # 1.1 å¦‚æœæŒ‡å®šäº†file_idsï¼Œä¼˜å…ˆæœç´¢è¿™äº›ä¸Šä¼ çš„æ–‡ä»¶
        if request.file_ids:
            uploaded_results = file_indexer.search_uploaded_files(
                request.query, 
                request.top_k or settings.TOP_K,
                file_ids=request.file_ids
            )
            # åˆå¹¶ç»“æœï¼Œä¸Šä¼ çš„æ–‡ä»¶ä¼˜å…ˆçº§æ›´é«˜
            search_results = uploaded_results + search_results
        
        # 2. åˆ¤æ–­æ˜¯å¦æœ‰RAGç»“æœï¼Œä»¥åŠç»“æœæ˜¯å¦ç›¸å…³
        has_rag_context = len(search_results) > 0
        is_relevant = False
        
        if has_rag_context:
            # æ£€æŸ¥ç›¸ä¼¼åº¦åˆ†æ•°ï¼šL2è·ç¦»è¶Šå°è¶Šç›¸ä¼¼
            # è®¾ç½®é˜ˆå€¼ï¼šå¦‚æœæœ€å¥½çš„ç»“æœåˆ†æ•° > 3.0ï¼Œè®¤ä¸ºä¸ç›¸å…³
            # (å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´è¿™ä¸ªé˜ˆå€¼)
            RELEVANCE_THRESHOLD = 3.0
            best_score = min(result.get('score', float('inf')) for result in search_results)
            is_relevant = best_score <= RELEVANCE_THRESHOLD
        
        if not has_rag_context or not is_relevant:
            # æƒ…å†µ1: RAGåº“ä¸ºç©º
            # æƒ…å†µ2: æ£€ç´¢åˆ°çš„æ–‡æ¡£ç›¸ä¼¼åº¦å¤ªä½ï¼ˆä¸ç›¸å…³ï¼‰
            # ç›´æ¥ä½¿ç”¨LLMå›ç­”ï¼Œä¸ä¾èµ–ä¸Šä¸‹æ–‡
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·ç›´æ¥å›ç­”é—®é¢˜ã€‚"
            user_prompt = request.query
            use_rag = False
        else:
            # æœ‰ç›¸å…³çš„RAGç»“æœï¼Œä½¿ç”¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡
            # æ„å»ºä¸Šä¸‹æ–‡
            context_parts = []
            for result in search_results:
                context_parts.append(result['text'])
            context = "\n\n".join(context_parts)
            
            # æ„å»ºPrompt
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œè¯·åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”é—®é¢˜ã€‚"
            user_prompt = f"åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼š\n\n{context}\n\nè¯·å›ç­”è¿™ä¸ªé—®é¢˜ï¼š{request.query}"
            use_rag = True
        
        # 3. è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆï¼ˆä½¿ç”¨ç»Ÿä¸€å®¢æˆ·ç«¯ï¼Œæ”¯æŒæ¨¡å‹é€‰æ‹©ï¼‰
        llm_result = unified_llm_client.chat(
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            max_tokens=2048,
            temperature=0.7,
            model=request.model,
            provider=request.provider
        )
        
        if "error" in llm_result:
            # å¦‚æœæ˜¯é…é¢ä¸è¶³é”™è¯¯ï¼Œè¿”å›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            error_msg = llm_result.get("error", "")
            if "é…é¢å·²ç”¨å®Œ" in error_msg or "é…é¢" in error_msg:
                raise HTTPException(
                    status_code=429,
                    detail=error_msg,
                    headers={"X-Quota-Info": str(llm_result.get("quota_info", {}))}
                )
            # è®°å½•è¯¦ç»†é”™è¯¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            logger.error(f"LLMè°ƒç”¨é”™è¯¯: {error_msg}")
            raise HTTPException(status_code=500, detail=f"LLMè°ƒç”¨å¤±è´¥: {error_msg}")
        
        answer = llm_result.get("content", "æ— æ³•ç”Ÿæˆç­”æ¡ˆ")
        # æ ¹æ®providerç¡®å®šä½¿ç”¨çš„æ¨¡å‹åç§°
        if request.provider == "gemini":
            model_used = llm_result.get("model", request.model or settings.GEMINI_DEFAULT_MODEL)
        else:
            model_used = settings.HKGAI_MODEL_ID
        
        # è·å–tokenä½¿ç”¨é‡ï¼ˆä»…Geminiè¿”å›ï¼‰
        tokens_info = None
        if "input_tokens" in llm_result:
            tokens_info = {
                "input": llm_result.get("input_tokens", 0),
                "output": llm_result.get("output_tokens", 0),
                "total": llm_result.get("total_tokens", 0)
            }
        
        # è·å–å‰©ä½™é…é¢ï¼ˆä»…Geminiæœ‰é…é¢é™åˆ¶ï¼‰
        quota_remaining = None
        if request.provider == "gemini":
            quota_info = usage_monitor.check_quota(model_used)
            quota_remaining = quota_info.get("remaining_requests", 0)
        
        # 4. æ ¼å¼åŒ–æ–‡æ¡£ç»“æœï¼ˆåªæœ‰ä½¿ç”¨RAGæ—¶æ‰è¿”å›contextï¼‰
        document_results = []
        if use_rag and has_rag_context:
            document_results = [
                DocumentResult(
                    text=result['text'],
                    source_file=result.get('source_file', 'unknown'),
                    score=float(result.get('score', 0.0))
                )
                for result in search_results
            ]
        
        return QueryResponse(
            answer=answer,
            context=document_results,
            query=request.query,
            answer_source="rag" if use_rag else "direct_llm",
            model_used=model_used,
            tokens_used=tokens_info,
            quota_remaining=quota_remaining
        )
    
    except HTTPException:
        # é‡æ–°æŠ›å‡ºHTTPå¼‚å¸¸ï¼ˆå¦‚é…é¢é”™è¯¯ï¼‰
        raise
    except Exception as e:
        # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        import traceback
        error_trace = traceback.format_exc()
        logger.error(f"RAGæŸ¥è¯¢é”™è¯¯è¯¦æƒ…:\n{error_trace}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")


@router.post("/agent_query", response_model=QueryResponse)
async def agent_query(request: QueryRequest):
    """
    Agentæ™ºèƒ½æŸ¥è¯¢æ¥å£
    
    æ¥æ”¶ç”¨æˆ·é—®é¢˜ï¼ŒAgentä¼šæ ¹æ®é—®é¢˜ç±»å‹è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„å·¥å…·ï¼ˆæœ¬åœ°çŸ¥è¯†åº“ã€ç½‘é¡µæœç´¢ã€å¤©æ°”æŸ¥è¯¢ç­‰ï¼‰
    æ”¯æŒæ¨¡å‹é€‰æ‹©å’Œç”¨é‡ç›‘æ§
    """
    try:
        # ä½¿ç”¨Agentå¤„ç†é—®é¢˜ï¼ˆAgenté»˜è®¤ä½¿ç”¨HKGAIï¼Œå¦‚æœæŒ‡å®šäº†Geminiæ¨¡å‹åˆ™ä½¿ç”¨Geminiï¼‰
        agent_result = agent.execute(request.query, model=request.model)
        
        # è·å–tokenä½¿ç”¨é‡å’Œæ¨¡å‹ä¿¡æ¯
        tokens_info = None
        model_used = settings.HKGAI_MODEL_ID  # Agenté»˜è®¤ä½¿ç”¨HKGAI
        quota_remaining = None
        
        # å¦‚æœè¿”å›äº†Geminiçš„tokenä¿¡æ¯ï¼Œè¯´æ˜ä½¿ç”¨äº†Gemini
        if "tokens" in agent_result and agent_result["tokens"]:
            tokens_info = agent_result["tokens"]
            if "model" in agent_result and agent_result["model"]:
                model_used = agent_result["model"]
                quota_info = usage_monitor.check_quota(model_used)
                quota_remaining = quota_info.get("remaining_requests", 0)
        
        # æ ¼å¼åŒ–å“åº”
        return QueryResponse(
            answer=agent_result["answer"],
            context=[],  # Agentæ¨¡å¼ä¸‹ä¸è¿”å›å…·ä½“æ–‡æ¡£ç‰‡æ®µ
            query=request.query,
            tools_used=agent_result.get("tools_used", []),
            answer_source="agent",
            model_used=model_used,
            tokens_used=tokens_info,
            quota_remaining=quota_remaining
        )
    
    except HTTPException:
        # é‡æ–°æŠ›å‡ºHTTPå¼‚å¸¸ï¼ˆå¦‚é…é¢é”™è¯¯ï¼‰
        raise
    except Exception as e:
        # è®°å½•è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        import traceback
        error_trace = traceback.format_exc()
        logger.error(f"AgentæŸ¥è¯¢é”™è¯¯è¯¦æƒ…:\n{error_trace}")
        raise HTTPException(status_code=500, detail=f"å¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)}")


@router.get("/usage/stats")
async def get_usage_stats(model: Optional[str] = None):
    """
    è·å–APIç”¨é‡ç»Ÿè®¡
    
    Args:
        model: æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›æ‰€æœ‰æ¨¡å‹çš„ç»Ÿè®¡
    """
    stats = usage_monitor.get_daily_stats(model)
    return stats


@router.get("/usage/quota")
async def check_quota(model: str = "gemini-2.0-flash"):
    """
    æ£€æŸ¥æŒ‡å®šæ¨¡å‹çš„é…é¢çŠ¶æ€
    
    Args:
        model: æ¨¡å‹åç§°
    """
    quota = usage_monitor.check_quota(model)
    return quota


@router.get("/models")
async def get_supported_models():
    """è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
    return unified_llm_client.get_supported_models()


@router.post("/upload", response_model=FileUploadResponse)
async def upload_file(file: UploadFile = FastAPIFile(...)):
    """
    æ–‡ä»¶ä¸Šä¼ æ¥å£
    
    æ”¯æŒä¸Šä¼ å¤šç§æ ¼å¼çš„æ–‡ä»¶ï¼š
    - PDFæ–‡ä»¶ (.pdf)
    - å›¾ç‰‡æ–‡ä»¶ (.png, .jpg, .jpeg, .gif) - æ”¯æŒOCR
    - ä»£ç æ–‡ä»¶ (.py, .js, .javaç­‰)
    - æ–‡æœ¬æ–‡ä»¶ (.txt, .md, .json, .csvç­‰)
    
    ä¸Šä¼ çš„æ–‡ä»¶ä¼šè‡ªåŠ¨è§£æã€å‘é‡åŒ–å¹¶ç´¢å¼•åˆ°Milvus
    """
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        file_content = await file.read()
        
        # ä¿å­˜æ–‡ä»¶
        result = file_storage.save_file(
            file_content=file_content,
            filename=file.filename,
            mime_type=file.content_type
        )
        
        # å¼‚æ­¥å¤„ç†å’Œç´¢å¼•æ–‡ä»¶ï¼ˆä¸é˜»å¡å“åº”ï¼‰
        if not result.get("already_exists") or not result.get("processed"):
            asyncio.create_task(_process_and_index_file(result["file_id"]))
            message = "æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ­£åœ¨åå°å¤„ç†å’Œç´¢å¼•..."
        else:
            message = "æ–‡ä»¶å·²å­˜åœ¨ä¸”å·²å¤„ç†"
        
        file_info = file_storage.get_file(result["file_id"])
        
        return FileUploadResponse(
            file_id=result["file_id"],
            filename=result["filename"],
            file_type=result["file_type"],
            file_size=result["file_size"],
            uploaded_at=file_info["uploaded_at"] if file_info else "",
            processed=result.get("processed", False),
            already_exists=result.get("already_exists", False),
            message=message
        )
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")


async def _process_and_index_file(file_id: str):
    """å¼‚æ­¥å¤„ç†å’Œç´¢å¼•æ–‡ä»¶"""
    try:
        index_result = file_indexer.index_file(file_id)
        logger.info(f"æ–‡ä»¶ {file_id} å¤„ç†å®Œæˆ: {index_result}")
    except Exception as e:
        logger.error(f"æ–‡ä»¶ {file_id} å¤„ç†å¤±è´¥: {e}")


@router.get("/files")
async def list_files(file_type: Optional[str] = None, processed: Optional[bool] = None):
    """
    åˆ—å‡ºæ‰€æœ‰ä¸Šä¼ çš„æ–‡ä»¶
    
    Args:
        file_type: æ–‡ä»¶ç±»å‹è¿‡æ»¤ (pdf, image, code, text)
        processed: æ˜¯å¦å·²å¤„ç†è¿‡æ»¤ (true/false)
    """
    try:
        files = file_storage.list_files(file_type=file_type, processed=processed)
        return {"files": files, "total": len(files)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.get("/files/{file_id}")
async def get_file_info(file_id: str):
    """è·å–æ–‡ä»¶è¯¦ç»†ä¿¡æ¯"""
    file_info = file_storage.get_file(file_id)
    if not file_info:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    return file_info


@router.delete("/files/{file_id}")
async def delete_file(file_id: str):
    """åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶"""
    success = file_storage.delete_file(file_id)
    if not success:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    return {"message": "æ–‡ä»¶åˆ é™¤æˆåŠŸ", "file_id": file_id}


@router.post("/files/{file_id}/reindex")
async def reindex_file(file_id: str):
    """é‡æ–°å¤„ç†å’Œç´¢å¼•æ–‡ä»¶"""
    try:
        result = file_indexer.index_file(file_id)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"é‡æ–°ç´¢å¼•å¤±è´¥: {str(e)}")


@router.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {
        "status": "ok",
        "service": "RAG API with Gemini",
        "milvus_host": settings.MILVUS_HOST,
        "milvus_port": settings.MILVUS_PORT,
        "default_model": settings.GEMINI_DEFAULT_MODEL if settings.GEMINI_ENABLED else settings.HKGAI_MODEL_ID
    }


@router.get("/cache/stats")
async def get_cache_statistics():
    """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = get_cache_stats()
        return {
            "cache_enabled": settings.USE_CACHE,
            "statistics": stats
        }
    except Exception as e:
        logger.error(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {str(e)}")


@router.post("/cache/clear")
async def clear_cache_endpoint(cache_type: str = "all"):
    """
    æ¸…ç©ºç¼“å­˜
    
    Args:
        cache_type: ç¼“å­˜ç±»å‹ ("query", "embedding", "all")
    """
    try:
        if cache_type not in ("query", "embedding", "all"):
            raise HTTPException(status_code=400, detail="cache_typeå¿…é¡»æ˜¯'query'ã€'embedding'æˆ–'all'")
        
        clear_cache(cache_type)
        return {
            "message": f"ç¼“å­˜å·²æ¸…ç©º: {cache_type}",
            "cache_type": cache_type
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {str(e)}")


# ========== è¯­éŸ³æŸ¥è¯¢è¾…åŠ©å‡½æ•° ==========

def _parse_voice_request_params(request: Optional[str]) -> Dict:
    """è§£æè¯­éŸ³æŸ¥è¯¢è¯·æ±‚å‚æ•°"""
    default_params = {
        "language": None,
        "use_wake_word": True,
        "use_agent": True
    }
    
    if not request:
        return default_params
    
    try:
        import json
        params = json.loads(request)
        return {
            "language": params.get("language"),
            "use_wake_word": params.get("use_wake_word", True),
            "use_agent": params.get("use_agent", True)
        }
    except:
        return default_params


async def _process_voice_query_with_agent(query_text: str, model: Optional[str] = None) -> Dict:
    """ä½¿ç”¨Agentå¤„ç†æŸ¥è¯¢"""
    agent_result = agent.execute(query_text, model=model)
    return {
        "answer": agent_result.get("answer", "æ— æ³•ç”Ÿæˆç­”æ¡ˆ"),
        "tools_used": agent_result.get("tools_used", []),
        "tokens_info": agent_result.get("tokens", None),
        "model_used": settings.HKGAI_MODEL_ID
    }


async def _process_voice_query_with_rag(query_text: str) -> Dict:
    """ä½¿ç”¨RAGå¤„ç†æŸ¥è¯¢"""
    search_results = retriever.search(query_text, top_k=settings.TOP_K)
    
    if search_results:
        context = "\n\n".join([r['text'] for r in search_results[:3]])
        llm_result = unified_llm_client.chat(
            system_prompt="åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚",
            user_prompt=f"ä¸Šä¸‹æ–‡ï¼š\n{context}\n\né—®é¢˜ï¼š{query_text}",
            max_tokens=2048
        )
        answer = llm_result.get("content", "æ— æ³•ç”Ÿæˆç­”æ¡ˆ")
        tools_used = ["rag"]
    else:
        llm_result = unified_llm_client.chat(
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚",
            user_prompt=query_text,
            max_tokens=2048
        )
        answer = llm_result.get("content", "æ— æ³•ç”Ÿæˆç­”æ¡ˆ")
        tools_used = ["direct_llm"]
    
    return {
        "answer": answer,
        "tools_used": tools_used,
        "tokens_info": None,
        "model_used": settings.HKGAI_MODEL_ID
    }


@router.post("/voice/query", response_model=VoiceQueryResponse)
async def voice_query(audio: UploadFile = FastAPIFile(...), request: Optional[str] = None):
    """
    ğŸ¤ Jarvisè¯­éŸ³æŸ¥è¯¢æ¥å£
    
    æ¥æ”¶éŸ³é¢‘æ–‡ä»¶ï¼Œè½¬æ¢ä¸ºæ–‡æœ¬ï¼Œæ£€æµ‹å”¤é†’è¯"Jarvis"ï¼Œç„¶åä½¿ç”¨Agentå›ç­”
    
    æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: wav, mp3, m4a, flacç­‰
    
    ä½¿ç”¨ç¤ºä¾‹:
    1. ç”¨æˆ·è¯´: "Jarvis, ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
    2. ç³»ç»Ÿæ£€æµ‹åˆ°"Jarvis"ï¼Œæå–æŸ¥è¯¢"ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
    3. Agentå¤„ç†æŸ¥è¯¢å¹¶ç”Ÿæˆç­”æ¡ˆ
    4. è¿”å›æ–‡æœ¬ç­”æ¡ˆï¼ˆå¯é€‰ï¼šç”Ÿæˆè¯­éŸ³å›å¤ï¼‰
    """
    if not settings.ENABLE_SPEECH:
        raise HTTPException(status_code=503, detail="è¯­éŸ³åŠŸèƒ½æœªå¯ç”¨")
    
    try:
        # æ£€æŸ¥è¯­éŸ³æ¨¡å—æ˜¯å¦å¯ç”¨
        try:
            from services.speech.voice_service import get_voice_service
        except ImportError:
            raise HTTPException(
                status_code=503,
                detail="è¯­éŸ³æ¨¡å—æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install openai-whisper soundfile edge-tts"
            )
        
        voice_service = get_voice_service()
        
        # 1. è¯»å–å¹¶è§£æéŸ³é¢‘æ–‡ä»¶
        audio_bytes = await audio.read()
        audio_format = audio.filename.split('.')[-1] if '.' in audio.filename else "wav"
        logger.info(f"æ”¶åˆ°è¯­éŸ³æŸ¥è¯¢: {audio.filename}, æ ¼å¼: {audio_format}, å¤§å°: {len(audio_bytes)} bytes")
        
        # 2. è§£æè¯·æ±‚å‚æ•°
        params = _parse_voice_request_params(request)
        
        # 3. è¯­éŸ³è½¬æ–‡æœ¬
        transcription_result = voice_service.transcribe_audio(
            audio_bytes=audio_bytes,
            audio_format=audio_format,
            language=params["language"]
        )
        
        if "error" in transcription_result:
            raise HTTPException(
                status_code=500,
                detail=f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {transcription_result['error']}"
            )
        
        transcribed_text = transcription_result.get("text", "").strip()
        detected_language = transcription_result.get("language", "unknown")
        confidence = transcription_result.get("confidence", 0.0)
        
        if not transcribed_text:
            raise HTTPException(status_code=400, detail="æœªèƒ½è¯†åˆ«è¯­éŸ³å†…å®¹ï¼Œè¯·æ£€æŸ¥éŸ³é¢‘è´¨é‡")
        
        # 4. æ£€æµ‹å”¤é†’è¯å¹¶æå–æŸ¥è¯¢
        wake_word_detected, query_text = voice_service.detect_and_extract_query(
            transcribed_text=transcribed_text,
            use_wake_word=params["use_wake_word"]
        )
        
        if not query_text:
            raise HTTPException(status_code=400, detail="æŸ¥è¯¢æ–‡æœ¬ä¸ºç©º")
        
        # 5. å¤„ç†æŸ¥è¯¢ï¼ˆAgentæˆ–RAGï¼‰
        if params["use_agent"]:
            query_result = await _process_voice_query_with_agent(query_text)
        else:
            query_result = await _process_voice_query_with_rag(query_text)
        
        # 6. ç”Ÿæˆè¯­éŸ³å›å¤ï¼ˆå¯é€‰ï¼‰
        answer_audio_url = None
        if settings.ENABLE_SPEECH and settings.USE_EDGE_TTS:
            audio_file = voice_service.generate_audio_response(
                text=query_result["answer"],
                language=detected_language
            )
            if audio_file:
                answer_audio_url = f"/audio/{os.path.basename(audio_file)}"
        
        # 7. è¿”å›ç»“æœ
        return VoiceQueryResponse(
            transcribed_text=transcribed_text,
            detected_language=detected_language,
            wake_word_detected=wake_word_detected,
            query_text=query_text,
            answer=query_result["answer"],
            answer_audio_url=answer_audio_url,
            tools_used=query_result["tools_used"],
            model_used=query_result["model_used"],
            tokens_used=query_result["tokens_info"],
            confidence=confidence
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è¯­éŸ³æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}")
        import traceback
        logger.debug(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"å¤„ç†è¯­éŸ³æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}")


@router.websocket("/voice/ws")
async def voice_websocket(websocket: WebSocket):
    """
    ğŸ¤ Jarviså®æ—¶è¯­éŸ³äº¤äº’WebSocketæ¥å£
    
    æ”¯æŒå®æ—¶è¯­éŸ³è¾“å…¥å’Œå“åº”ï¼Œç±»ä¼¼"Hey Siri"çš„äº¤äº’ä½“éªŒ
    
    ä½¿ç”¨æ–¹å¼ï¼š
    1. è¿æ¥WebSocket: ws://localhost:8000/api/voice/ws
    2. å‘é€éŸ³é¢‘æ•°æ®ï¼ˆbase64ç¼–ç ï¼‰
    3. æ¥æ”¶è½¬å½•æ–‡æœ¬å’Œå›ç­”
    
    å‰ç«¯é¡µé¢è®¿é—®: http://localhost:8000/voice
    """
    import uuid
    
    client_id = str(uuid.uuid4())
    
    try:
        from services.speech.websocket_handler import get_voice_ws_handler
        
        if not settings.ENABLE_SPEECH:
            await websocket.close(code=1008, reason="è¯­éŸ³åŠŸèƒ½æœªå¯ç”¨")
            return
        
        handler = get_voice_ws_handler()
        await handler.connect(websocket, client_id)
        
        # å‘é€è¿æ¥æˆåŠŸæ¶ˆæ¯
        await handler.send_message(client_id, {
            "type": "connected",
            "message": "Jarvisè¯­éŸ³åŠ©æ‰‹å·²è¿æ¥",
            "client_id": client_id,
            "wake_word": settings.WAKE_WORD
        })
        
        # æ¥æ”¶æ¶ˆæ¯å¾ªç¯
        while True:
            try:
                # æ¥æ”¶JSONæ¶ˆæ¯
                data = await websocket.receive_json()
                
                message_type = data.get("type", "")
                
                if message_type == "audio":
                    # å¤„ç†éŸ³é¢‘æ•°æ®
                    audio_data = data.get("data", "")
                    is_final = data.get("is_final", False)
                    audio_format = data.get("format", "webm")
                    await handler.handle_audio_chunk(client_id, audio_data, is_final, audio_format)
                
                elif message_type == "ping":
                    # å¿ƒè·³æ£€æµ‹
                    await handler.send_message(client_id, {
                        "type": "pong",
                        "timestamp": data.get("timestamp")
                    })
                
                elif message_type == "disconnect":
                    # å®¢æˆ·ç«¯ä¸»åŠ¨æ–­å¼€
                    break
                    
            except WebSocketDisconnect:
                logger.info(f"å®¢æˆ·ç«¯ {client_id} æ–­å¼€è¿æ¥")
                break
            except Exception as e:
                logger.error(f"WebSocketæ¶ˆæ¯å¤„ç†é”™è¯¯: {e}")
                await handler.send_message(client_id, {
                    "type": "error",
                    "message": str(e)
                })
    
    except Exception as e:
        logger.error(f"WebSocketè¿æ¥é”™è¯¯: {e}")
    finally:
        handler.disconnect(client_id)

