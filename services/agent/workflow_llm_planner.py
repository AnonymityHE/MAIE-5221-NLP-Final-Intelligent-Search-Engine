"""
LLMé©±åŠ¨çš„å·¥ä½œæµè§„åˆ’å™¨ - ä½¿ç”¨LLMæ™ºèƒ½åˆ†ææŸ¥è¯¢å¹¶ç”Ÿæˆæ‰§è¡Œè®¡åˆ’

å®ç°æ€è·¯ï¼š
1. ä½¿ç”¨LLMåˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œç†è§£æ„å›¾å’Œå¤æ‚åº¦
2. ç”Ÿæˆç»“æ„åŒ–çš„æ‰§è¡Œè®¡åˆ’ï¼ˆJSONæ ¼å¼ï¼‰
3. æå–æŸ¥è¯¢ä¸­çš„å®ä½“ï¼ˆå…¬å¸åã€åœ°ç‚¹ã€æ—¥æœŸç­‰ï¼‰
4. åŠ¨æ€å†³å®šéœ€è¦è°ƒç”¨å“ªäº›å·¥å…·å’Œæ­¥éª¤é¡ºåº

ç¤ºä¾‹ï¼š
æŸ¥è¯¢ï¼š"What was the impact of the latest NVIDIA earnings report on their stock price and how does it compare to AMD's?"

LLMç”Ÿæˆçš„è®¡åˆ’ï¼š
{
    "workflow_type": "multi_step_research",
    "requires_workflow": true,
    "steps": [
        {
            "step_id": 1,
            "tool": "web_search",
            "action": "æœç´¢NVIDIAæœ€æ–°è´¢æŠ¥",
            "query": "NVIDIA latest earnings report 2024",
            "reason": "éœ€è¦è·å–æœ€æ–°çš„è´¢æŠ¥ä¿¡æ¯"
        },
        {
            "step_id": 2,
            "tool": "finance",
            "action": "è·å–NVIDIAè‚¡ä»·",
            "query": "NVIDIA stock price",
            "entities": {"company": "NVIDIA", "symbol": "NVDA"},
            "reason": "éœ€è¦è·å–è´¢æŠ¥åçš„è‚¡ä»·å˜åŒ–"
        },
        {
            "step_id": 3,
            "tool": "finance",
            "action": "è·å–AMDè‚¡ä»·",
            "query": "AMD stock price",
            "entities": {"company": "AMD", "symbol": "AMD"},
            "reason": "éœ€è¦å¯¹æ¯”AMDçš„è‚¡ä»·è¡¨ç°"
        },
        {
            "step_id": 4,
            "tool": "synthesize",
            "action": "ç»¼åˆåˆ†æç»“æœ",
            "reason": "æ•´åˆæ‰€æœ‰ä¿¡æ¯ç”Ÿæˆå¯¹æ¯”åˆ†æ"
        }
    ],
    "entities": {
        "companies": ["NVIDIA", "AMD"],
        "topics": ["earnings report", "stock price"]
    }
}
"""
import json
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from services.llm.unified_client import unified_llm_client
from services.core.logger import logger


@dataclass
class WorkflowStep:
    """å·¥ä½œæµæ­¥éª¤å®šä¹‰"""
    step_id: int
    tool: str  # å·¥å…·åç§°ï¼šweb_search, finance, weather, transport, local_rag
    action: str  # åŠ¨ä½œæè¿°
    query: str  # æ‰§è¡ŒæŸ¥è¯¢
    entities: Dict[str, Any] = field(default_factory=dict)  # æå–çš„å®ä½“
    reason: str = ""  # æ‰§è¡ŒåŸå› 
    dependencies: List[int] = field(default_factory=list)  # ä¾èµ–çš„æ­¥éª¤ID
    result: Optional[Any] = None  # æ‰§è¡Œç»“æœ
    status: str = "pending"  # pending, running, completed, failed


@dataclass
class WorkflowPlan:
    """å·¥ä½œæµæ‰§è¡Œè®¡åˆ’"""
    workflow_type: str  # å·¥ä½œæµç±»å‹
    requires_workflow: bool  # æ˜¯å¦éœ€è¦å¤šæ­¥éª¤å·¥ä½œæµ
    steps: List[WorkflowStep]  # æ­¥éª¤åˆ—è¡¨
    entities: Dict[str, Any] = field(default_factory=dict)  # å…¨å±€æå–çš„å®ä½“
    confidence: float = 0.0  # LLMè§„åˆ’çš„ç½®ä¿¡åº¦
    reasoning: str = ""  # LLMçš„æ¨ç†è¿‡ç¨‹


class LLMWorkflowPlanner:
    """LLMé©±åŠ¨çš„å·¥ä½œæµè§„åˆ’å™¨"""
    
    def __init__(self, available_tools: List[str]):
        """
        åˆå§‹åŒ–è§„åˆ’å™¨
        
        Args:
            available_tools: å¯ç”¨çš„å·¥å…·åˆ—è¡¨
        """
        self.available_tools = available_tools
        logger.info(f"LLMå·¥ä½œæµè§„åˆ’å™¨åˆå§‹åŒ–ï¼Œå¯ç”¨å·¥å…·: {', '.join(available_tools)}")
    
    def analyze_query(self, query: str) -> WorkflowPlan:
        """
        ä½¿ç”¨LLMåˆ†ææŸ¥è¯¢å¹¶ç”Ÿæˆå·¥ä½œæµè®¡åˆ’
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            å·¥ä½œæµè®¡åˆ’
        """
        logger.info(f"ğŸ§  LLMå¼€å§‹åˆ†ææŸ¥è¯¢: '{query[:100]}...'")
        
        # æ„å»ºLLMæç¤ºè¯
        system_prompt = self._build_planner_prompt()
        user_prompt = f"""
è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·æŸ¥è¯¢ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦å¤šæ­¥éª¤å·¥ä½œæµï¼Œå¹¶ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ã€‚

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
"""
        
        try:
            # è°ƒç”¨LLMè¿›è¡Œè§„åˆ’
            llm_result = unified_llm_client.chat(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                max_tokens=1500,
                temperature=0.3,  # ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„è§„åˆ’ç»“æœ
                provider="hkgai"  # ä½¿ç”¨HKGAIè¿›è¡Œè§„åˆ’
            )
            
            if "error" in llm_result:
                logger.error(f"LLMè§„åˆ’å¤±è´¥: {llm_result['error']}")
                return self._create_simple_plan(query)
            
            # è§£æLLMè¿”å›çš„JSON
            plan_json = self._extract_json_from_response(llm_result.get("content", ""))
            
            if not plan_json:
                logger.warning("æ— æ³•ä»LLMå“åº”ä¸­æå–JSONï¼Œä½¿ç”¨ç®€å•è§„åˆ’")
                return self._create_simple_plan(query)
            
            # æ„å»ºWorkflowPlanå¯¹è±¡
            workflow_plan = self._parse_plan_json(plan_json, query)
            
            logger.info(f"âœ… LLMè§„åˆ’å®Œæˆ: å·¥ä½œæµç±»å‹={workflow_plan.workflow_type}, "
                       f"éœ€è¦å·¥ä½œæµ={workflow_plan.requires_workflow}, "
                       f"æ­¥éª¤æ•°={len(workflow_plan.steps)}")
            
            return workflow_plan
            
        except Exception as e:
            logger.error(f"LLMå·¥ä½œæµè§„åˆ’å¼‚å¸¸: {e}")
            return self._create_simple_plan(query)
    
    def _build_planner_prompt(self) -> str:
        """æ„å»ºLLMè§„åˆ’å™¨çš„ç³»ç»Ÿæç¤ºè¯"""
        tools_description = self._get_tools_description()
        
        return f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å·¥ä½œæµè§„åˆ’å™¨ï¼Œè´Ÿè´£åˆ†æç”¨æˆ·æŸ¥è¯¢å¹¶ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ã€‚

å¯ç”¨å·¥å…·ï¼š
{tools_description}

ä½ çš„ä»»åŠ¡ï¼š
1. åˆ†æç”¨æˆ·æŸ¥è¯¢çš„å¤æ‚åº¦å’Œæ„å›¾
2. åˆ¤æ–­æ˜¯å¦éœ€è¦å¤šæ­¥éª¤å·¥ä½œæµï¼ˆå•ä¸€å·¥å…·å¯ä»¥è§£å†³çš„æŸ¥è¯¢ä¸éœ€è¦å·¥ä½œæµï¼‰
3. å¦‚æœéœ€è¦å·¥ä½œæµï¼Œç”Ÿæˆç»“æ„åŒ–çš„æ‰§è¡Œè®¡åˆ’
4. ä»æŸ¥è¯¢ä¸­æå–å…³é”®å®ä½“ï¼ˆå…¬å¸åã€åœ°ç‚¹ã€æ—¥æœŸã€è‚¡ç¥¨ä»£ç ç­‰ï¼‰

åˆ¤æ–­æ ‡å‡† - éœ€è¦å·¥ä½œæµçš„æƒ…å†µï¼š
- æŸ¥è¯¢æ¶‰åŠå¯¹æ¯”åˆ†æï¼ˆå¦‚"æ¯”è¾ƒAå’ŒB"ï¼‰
- æŸ¥è¯¢éœ€è¦å¤šä¸ªæ•°æ®æºï¼ˆå¦‚"è´¢æŠ¥å¯¹è‚¡ä»·çš„å½±å“"ï¼‰
- æŸ¥è¯¢åŒ…å«å¤šä¸ªå­é—®é¢˜
- æŸ¥è¯¢éœ€è¦æ—¶åºåˆ†ææˆ–å†å²å¯¹æ¯”

åˆ¤æ–­æ ‡å‡† - ä¸éœ€è¦å·¥ä½œæµçš„æƒ…å†µï¼š
- ç®€å•çš„å•ä¸€æŸ¥è¯¢ï¼ˆå¦‚"ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·"ï¼‰
- åªéœ€è¦ä¸€ä¸ªå·¥å…·å°±èƒ½å›ç­”
- æŸ¥è¯¢æ˜¯çŸ¥è¯†é—®ç­”ç±»å‹

è¿”å›JSONæ ¼å¼ï¼š
{{
    "requires_workflow": true/false,
    "workflow_type": "å·¥ä½œæµç±»å‹ï¼ˆå¦‚multi_step_research, comparison_analysis, time_seriesç­‰ï¼‰",
    "reasoning": "ä½ çš„æ¨ç†è¿‡ç¨‹",
    "confidence": 0.0-1.0çš„ç½®ä¿¡åº¦,
    "steps": [
        {{
            "step_id": 1,
            "tool": "å·¥å…·åç§°",
            "action": "åŠ¨ä½œæè¿°",
            "query": "å…·ä½“çš„æŸ¥è¯¢å­—ç¬¦ä¸²",
            "entities": {{"æå–çš„å®ä½“"}},
            "reason": "ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸€æ­¥",
            "dependencies": [ä¾èµ–çš„æ­¥éª¤IDåˆ—è¡¨]
        }}
    ],
    "entities": {{
        "æå–çš„å…¨å±€å®ä½“"
    }}
}}

é‡è¦ï¼š
- å¦‚æœrequires_workflowä¸ºfalseï¼Œstepsæ•°ç»„å¯ä»¥ä¸ºç©ºæˆ–åªåŒ…å«ä¸€ä¸ªæ­¥éª¤
- æ­¥éª¤é¡ºåºè¦åˆç†ï¼Œè€ƒè™‘ä¾èµ–å…³ç³»
- queryå­—æ®µè¦å…·ä½“å¯æ‰§è¡Œï¼Œä¸è¦å¤ªæ¨¡ç³Š
- ä¼˜å…ˆä½¿ç”¨ä¸“ä¸šå·¥å…·ï¼ˆfinanceã€weatherã€transportï¼‰è€Œéweb_search
- åªè¿”å›JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—
"""
    
    def _get_tools_description(self) -> str:
        """è·å–å·¥å…·æè¿°"""
        descriptions = {
            "local_rag": "æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢ - ä»å·²ç´¢å¼•çš„æ–‡æ¡£ä¸­æ£€ç´¢ä¿¡æ¯",
            "web_search": "ç½‘é¡µæœç´¢ - æœç´¢äº’è”ç½‘è·å–æœ€æ–°ä¿¡æ¯",
            "finance": "é‡‘èå·¥å…· - è·å–è‚¡ç¥¨ã€åŠ å¯†è´§å¸ä»·æ ¼å’Œé‡‘èæ•°æ®",
            "weather": "å¤©æ°”å·¥å…· - è·å–å½“å‰å¤©æ°”å’Œé¢„æŠ¥ä¿¡æ¯",
            "transport": "äº¤é€šå·¥å…· - æŸ¥è¯¢æ—…è¡Œæ—¶é—´ã€è·¯çº¿å’Œç‰©æµä¿¡æ¯"
        }
        
        result = []
        for tool in self.available_tools:
            if tool in descriptions:
                result.append(f"- {tool}: {descriptions[tool]}")
        
        return "\n".join(result)
    
    def _extract_json_from_response(self, response: str) -> Optional[Dict]:
        """ä»LLMå“åº”ä¸­æå–JSON"""
        try:
            # å°è¯•ç›´æ¥è§£æ
            return json.loads(response)
        except json.JSONDecodeError:
            # å°è¯•æå–JSONä»£ç å—
            import re
            json_pattern = r'```(?:json)?\s*(\{.*?\})\s*```'
            matches = re.findall(json_pattern, response, re.DOTALL)
            if matches:
                try:
                    return json.loads(matches[0])
                except json.JSONDecodeError:
                    pass
            
            # å°è¯•æŸ¥æ‰¾ç¬¬ä¸€ä¸ª{åˆ°æœ€åä¸€ä¸ª}
            start_idx = response.find('{')
            end_idx = response.rfind('}')
            if start_idx != -1 and end_idx != -1 and start_idx < end_idx:
                try:
                    return json.loads(response[start_idx:end_idx+1])
                except json.JSONDecodeError:
                    pass
            
            return None
    
    def _parse_plan_json(self, plan_json: Dict, original_query: str) -> WorkflowPlan:
        """å°†JSONè½¬æ¢ä¸ºWorkflowPlanå¯¹è±¡"""
        requires_workflow = plan_json.get("requires_workflow", False)
        workflow_type = plan_json.get("workflow_type", "simple_query")
        reasoning = plan_json.get("reasoning", "")
        confidence = plan_json.get("confidence", 0.5)
        entities = plan_json.get("entities", {})
        
        steps = []
        for step_data in plan_json.get("steps", []):
            step = WorkflowStep(
                step_id=step_data.get("step_id", len(steps) + 1),
                tool=step_data.get("tool", "local_rag"),
                action=step_data.get("action", ""),
                query=step_data.get("query", original_query),
                entities=step_data.get("entities", {}),
                reason=step_data.get("reason", ""),
                dependencies=step_data.get("dependencies", [])
            )
            steps.append(step)
        
        return WorkflowPlan(
            workflow_type=workflow_type,
            requires_workflow=requires_workflow,
            steps=steps,
            entities=entities,
            confidence=confidence,
            reasoning=reasoning
        )
    
    def _create_simple_plan(self, query: str) -> WorkflowPlan:
        """åˆ›å»ºç®€å•çš„å•æ­¥éª¤è®¡åˆ’ï¼ˆLLMè§„åˆ’å¤±è´¥æ—¶çš„fallbackï¼‰"""
        logger.info("åˆ›å»ºç®€å•çš„fallbackè®¡åˆ’")
        return WorkflowPlan(
            workflow_type="simple_query",
            requires_workflow=False,
            steps=[
                WorkflowStep(
                    step_id=1,
                    tool="local_rag",
                    action="ç›´æ¥å›ç­”",
                    query=query,
                    reason="LLMè§„åˆ’å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æŸ¥è¯¢æ¨¡å¼"
                )
            ],
            entities={},
            confidence=0.3,
            reasoning="LLMè§„åˆ’å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•æ¨¡å¼"
        )
    
    def extract_entities(self, query: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨LLMä»æŸ¥è¯¢ä¸­æå–å®ä½“
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            
        Returns:
            æå–çš„å®ä½“å­—å…¸
        """
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªå®ä½“æå–ä¸“å®¶ã€‚ä»ç”¨æˆ·æŸ¥è¯¢ä¸­æå–å…³é”®å®ä½“ã€‚

éœ€è¦æå–çš„å®ä½“ç±»å‹ï¼š
- companies: å…¬å¸åç§°åˆ—è¡¨
- stock_symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
- locations: åœ°ç‚¹åˆ—è¡¨
- dates: æ—¥æœŸ/æ—¶é—´è¡¨è¾¾
- topics: ä¸»é¢˜/å…³é”®è¯åˆ—è¡¨
- numbers: æ•°å­—å’Œåº¦é‡

è¿”å›JSONæ ¼å¼ï¼š
{
    "companies": [...],
    "stock_symbols": [...],
    "locations": [...],
    "dates": [...],
    "topics": [...],
    "numbers": [...]
}

åªè¿”å›JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚"""
        
        user_prompt = f"è¯·ä»ä»¥ä¸‹æŸ¥è¯¢ä¸­æå–å®ä½“ï¼š\n\n{query}"
        
        try:
            llm_result = unified_llm_client.chat(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                max_tokens=500,
                temperature=0.1,
                provider="hkgai"
            )
            
            if "error" not in llm_result:
                entities_json = self._extract_json_from_response(llm_result.get("content", ""))
                if entities_json:
                    return entities_json
            
        except Exception as e:
            logger.error(f"å®ä½“æå–å¤±è´¥: {e}")
        
        return {}


# å…¨å±€è§„åˆ’å™¨å®ä¾‹
_llm_planner: Optional[LLMWorkflowPlanner] = None


def get_llm_workflow_planner(tools: List[str]) -> LLMWorkflowPlanner:
    """è·å–æˆ–åˆ›å»ºLLMå·¥ä½œæµè§„åˆ’å™¨å®ä¾‹"""
    global _llm_planner
    if _llm_planner is None:
        _llm_planner = LLMWorkflowPlanner(tools)
    return _llm_planner

