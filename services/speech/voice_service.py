"""
è¯­éŸ³æœåŠ¡æ•´åˆæ¨¡å— - å°è£…è¯­éŸ³æŸ¥è¯¢çš„å®Œæ•´æµç¨‹
æ”¯æŒåŒå¼•æ“STTï¼šHKGAIï¼ˆç²¤è¯­ä¼˜åŒ–ï¼‰ + Whisperï¼ˆå¤šè¯­è¨€ï¼‰
"""
from typing import Dict, Optional, Tuple
from services.core.logger import logger
from services.core.config import settings


class VoiceService:
    """è¯­éŸ³æœåŠ¡æ•´åˆç±» - ç»Ÿä¸€å¤„ç†è¯­éŸ³æŸ¥è¯¢æµç¨‹"""
    
    def __init__(self):
        self._stt = None
        self._hkgai_stt = None  # æ–°å¢ï¼šHKGAI STTå®¢æˆ·ç«¯
        self._hkgai_tts = None  # æ–°å¢ï¼šHKGAI TTSå®¢æˆ·ç«¯ï¼ˆç²¤è¯­ä¼˜åŒ–ï¼‰
        self._wake_word_detector = None
        self._tts = None
    
    def _get_stt(self):
        """è·å–STTå®ä¾‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
        if self._stt is None:
            from services.speech import get_whisper_stt, reload_whisper_model
            
            # å¼ºåˆ¶æ¸…é™¤æ‰€æœ‰æ¨¡å‹ç¼“å­˜ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°é…ç½®
            logger.info(f"å‡†å¤‡åŠ è½½Whisperæ¨¡å‹: {settings.WHISPER_MODEL_SIZE}")
            for old_model in ['base', 'small', 'medium', 'large']:
                if old_model != settings.WHISPER_MODEL_SIZE:
                    reload_whisper_model(old_model)
            
            self._stt = get_whisper_stt(model_size=settings.WHISPER_MODEL_SIZE)
            
            # éªŒè¯æ¨¡å‹æ˜¯å¦æ­£ç¡®åŠ è½½
            if self._stt and self._stt.is_available():
                actual_model = getattr(self._stt, 'model_name', 'unknown')
                expected_model = settings.WHISPER_MODEL_SIZE
                if actual_model != expected_model:
                    logger.error(f"âŒ æ¨¡å‹ä¸åŒ¹é…ï¼æœŸæœ›: {expected_model}, å®é™…: {actual_model}")
                    logger.error(f"âŒ è¿™å¯èƒ½å¯¼è‡´è¯†åˆ«å‡†ç¡®åº¦ä½ï¼è¯·æ£€æŸ¥é…ç½®ã€‚")
                else:
                    logger.info(f"âœ… Whisperæ¨¡å‹åŠ è½½æˆåŠŸ: {actual_model}")
        return self._stt
    
    def _get_wake_word_detector(self):
        """è·å–å”¤é†’è¯æ£€æµ‹å™¨ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
        if self._wake_word_detector is None:
            from services.speech import get_jarvis_detector
            self._wake_word_detector = get_jarvis_detector()
        return self._wake_word_detector
    
    def _get_tts(self):
        """è·å–TTSå®ä¾‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
        if self._tts is None:
            from services.speech import get_tts
            self._tts = get_tts(use_edge_tts=settings.USE_EDGE_TTS)
        return self._tts
    
    def _get_hkgai_stt(self):
        """è·å–HKGAI STTå®ä¾‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
        if self._hkgai_stt is None:
            try:
                from services.speech.hkgai_stt import get_hkgai_client
                self._hkgai_stt = get_hkgai_client()
                if self._hkgai_stt.is_available():
                    logger.info("âœ… HKGAIè¯­éŸ³è¯†åˆ«å·²åŠ è½½ï¼ˆç²¤è¯­ä¼˜åŒ–ï¼‰")
                else:
                    logger.warning("âš ï¸  HKGAIè¯­éŸ³è¯†åˆ«æœªé…ç½®")
            except Exception as e:
                logger.warning(f"âš ï¸  HKGAI STTåŠ è½½å¤±è´¥: {e}")
                self._hkgai_stt = None
        return self._hkgai_stt
    
    def _get_hkgai_tts(self):
        """è·å–HKGAI TTSå®ä¾‹ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰"""
        if self._hkgai_tts is None:
            try:
                from services.speech.hkgai_tts import get_hkgai_tts_client
                self._hkgai_tts = get_hkgai_tts_client()
                if self._hkgai_tts.is_available():
                    logger.info("âœ… HKGAIè¯­éŸ³åˆæˆå·²åŠ è½½ï¼ˆç²¤è¯­/æ™®é€šè¯ï¼‰")
                else:
                    logger.warning("âš ï¸  HKGAI TTSæœªé…ç½®")
            except Exception as e:
                logger.warning(f"âš ï¸  HKGAI TTSåŠ è½½å¤±è´¥: {e}")
                self._hkgai_tts = None
        return self._hkgai_tts
    
    def transcribe_audio(
        self,
        audio_bytes: bytes,
        audio_format: str,
        language: Optional[str] = None,
        prefer_hkgai: bool = True  # æ–°å¢ï¼šæ˜¯å¦ä¼˜å…ˆä½¿ç”¨HKGAIï¼ˆç²¤è¯­åœºæ™¯ï¼‰
    ) -> Dict:
        """
        å°†éŸ³é¢‘è½¬æ¢ä¸ºæ–‡æœ¬ï¼ˆæ”¯æŒåŒå¼•æ“STTï¼šHKGAI + Whisperï¼‰
        
        Args:
            audio_bytes: éŸ³é¢‘å­—èŠ‚æ•°æ®
            audio_format: éŸ³é¢‘æ ¼å¼ï¼ˆwav, mp3ç­‰ï¼‰
            language: æŒ‡å®šè¯­è¨€ï¼ˆå¯é€‰ï¼‰
                - None: è‡ªåŠ¨æ£€æµ‹ï¼ˆæ¨èï¼Œæ”¯æŒä¸­æ–‡ã€ç²¤è¯­ã€è‹±è¯­æ··åˆï¼‰
                - "zh": å¼ºåˆ¶ä¸­æ–‡ï¼ˆæ™®é€šè¯ï¼‰
                - "yue": å¼ºåˆ¶ç²¤è¯­ï¼ˆä¼˜å…ˆä½¿ç”¨HKGAIï¼‰
                - "en": å¼ºåˆ¶è‹±è¯­
                - "auto": è‡ªåŠ¨æ£€æµ‹
            prefer_hkgai: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨HKGAIï¼ˆç²¤è¯­ä¼˜åŒ–ï¼‰
            
        Returns:
            è½¬å½•ç»“æœå­—å…¸
        """
        # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨HKGAIï¼ˆç²¤è¯­åœºæ™¯ï¼‰
        use_hkgai_first = (
            prefer_hkgai and 
            settings.USE_CANTONESE_API and 
            (language == "yue" or language == "zh" or language is None)
        )
        
        # å°è¯•ä½¿ç”¨HKGAIï¼ˆç²¤è¯­ä¼˜åŒ–ï¼‰
        if use_hkgai_first:
            hkgai_stt = self._get_hkgai_stt()
            if hkgai_stt and hkgai_stt.is_available():
                logger.info("ğŸ¤ ä½¿ç”¨HKGAIè¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼ˆç²¤è¯­ä¼˜åŒ–ï¼‰...")
                
                hkgai_result = hkgai_stt.recognize(audio_bytes)
                
                if hkgai_result.get("success"):
                    logger.info(f"âœ… HKGAIè¯†åˆ«æˆåŠŸ: '{hkgai_result['text'][:50]}...'")
                    # æ·»åŠ ç½®ä¿¡åº¦ä¿¡æ¯
                    hkgai_result['confidence'] = hkgai_result.get('confidence', 0.95)
                    return hkgai_result
                else:
                    logger.warning(f"âš ï¸  HKGAIè¯†åˆ«å¤±è´¥ï¼Œfallbackåˆ°Whisper: {hkgai_result.get('error')}")
        
        # ä½¿ç”¨Whisperï¼ˆä½œä¸ºä¸»è¦å¼•æ“æˆ–fallbackï¼‰
        logger.info("ğŸ¤ ä½¿ç”¨Whisperè¿›è¡Œè¯­éŸ³è¯†åˆ«...")
        stt = self._get_stt()
        if not stt or not stt.is_available():
            return {
                "error": "è¯­éŸ³è¯†åˆ«æœåŠ¡ä¸å¯ç”¨",
                "text": "",
                "language": None
            }
        
        # å¦‚æœæœªæŒ‡å®šè¯­è¨€ï¼Œä½¿ç”¨è‡ªåŠ¨æ£€æµ‹ï¼ˆæ”¯æŒå¤šè¯­è¨€ï¼‰
        if language is None:
            logger.debug("ä½¿ç”¨è‡ªåŠ¨è¯­è¨€æ£€æµ‹ï¼ˆæ”¯æŒä¸­æ–‡ã€ç²¤è¯­ã€è‹±è¯­ï¼‰")
        
        result = stt.transcribe_bytes(
            audio_bytes=audio_bytes,
            audio_format=audio_format,
            language=language
        )
        
        if "error" not in result:
            transcribed_text = result.get('text', '')
            detected_language = result.get('language', 'unknown')
            confidence = result.get('confidence', 0)
            
            # è¯¦ç»†è®°å½•è¯­è¨€ä¿¡æ¯
            lang_info = ""
            if detected_language == "yue":
                lang_info = "ï¼ˆç²¤è¯­ï¼‰"
            elif detected_language == "zh":
                lang_info = "ï¼ˆä¸­æ–‡/æ™®é€šè¯ï¼‰"
            elif detected_language == "en":
                lang_info = "ï¼ˆè‹±è¯­ï¼‰"
            elif detected_language == "mixed":
                lang_info = "ï¼ˆæ··åˆè¯­è¨€ï¼‰"
            
            logger.info(
                f"âœ… Whisperè¯†åˆ«å®Œæˆ: '{transcribed_text[:50]}...' "
                f"(è¯­è¨€: {detected_language}{lang_info}, ç½®ä¿¡åº¦: {confidence:.2f})"
            )
        
        return result
    
    def detect_and_extract_query(
        self,
        transcribed_text: str,
        use_wake_word: bool = True
    ) -> Tuple[bool, str]:
        """
        æ£€æµ‹å”¤é†’è¯å¹¶æå–æŸ¥è¯¢æ–‡æœ¬
        
        Args:
            transcribed_text: è½¬å½•çš„æ–‡æœ¬
            use_wake_word: æ˜¯å¦ä½¿ç”¨å”¤é†’è¯æ£€æµ‹
            
        Returns:
            (æ˜¯å¦æ£€æµ‹åˆ°å”¤é†’è¯, æŸ¥è¯¢æ–‡æœ¬)
        """
        if not use_wake_word:
            return False, transcribed_text.strip()
        
        detector = self._get_wake_word_detector()
        wake_word_detected = detector.detect_in_text(transcribed_text)
        
        if wake_word_detected:
            query_text = detector.extract_query_after_wake_word(transcribed_text)
            logger.info(f"æ£€æµ‹åˆ°å”¤é†’è¯'Jarvis'ï¼Œæå–æŸ¥è¯¢: '{query_text[:50]}...'")
            return True, query_text
        else:
            logger.info("æœªæ£€æµ‹åˆ°å”¤é†’è¯ï¼Œä½¿ç”¨å®Œæ•´è½¬å½•æ–‡æœ¬ä½œä¸ºæŸ¥è¯¢")
            return False, transcribed_text.strip()
    
    def generate_audio_response(
        self,
        text: str,
        language: str = "zh",
        prefer_hkgai: bool = True  # æ–°å¢ï¼šæ˜¯å¦ä¼˜å…ˆä½¿ç”¨HKGAIï¼ˆç²¤è¯­/æ™®é€šè¯åœºæ™¯ï¼‰
    ) -> Optional[str]:
        """
        ç”Ÿæˆè¯­éŸ³å›å¤ï¼ˆæ”¯æŒåŒå¼•æ“TTSï¼šHKGAI + Edge TTSï¼‰
        
        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            language: è¯­è¨€ä»£ç 
                - "zh": æ™®é€šè¯
                - "yue": ç²¤è¯­
                - "en": è‹±è¯­
            prefer_hkgai: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨HKGAIï¼ˆç²¤è¯­/æ™®é€šè¯åœºæ™¯ï¼‰
            
        Returns:
            éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæˆåŠŸï¼‰æˆ–None
        """
        if not settings.ENABLE_SPEECH:
            return None
        
        # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨HKGAI TTSï¼ˆç²¤è¯­æˆ–æ™®é€šè¯åœºæ™¯ï¼‰
        use_hkgai_first = (
            prefer_hkgai and 
            (language in ["zh", "yue", "zh-CN", "zh-HK"])
        )
        
        # å°è¯•ä½¿ç”¨HKGAI TTSï¼ˆç²¤è¯­/æ™®é€šè¯ä¼˜åŒ–ï¼‰
        if use_hkgai_first:
            hkgai_tts = self._get_hkgai_tts()
            if hkgai_tts and hkgai_tts.is_available():
                logger.info("ğŸ¤ ä½¿ç”¨HKGAI TTSåˆæˆè¯­éŸ³ï¼ˆç²¤è¯­/æ™®é€šè¯ä¼˜åŒ–ï¼‰...")
                
                # ç¡®å®šHKGAIè¯­è¨€
                hkgai_lang = "cantonese" if language in ["yue", "zh-HK"] else "mandarin"
                
                audio_file = hkgai_tts.synthesize(
                    text=text,
                    language=hkgai_lang,
                    voice="female"  # é»˜è®¤å¥³å£°
                )
                
                if audio_file:
                    logger.info(f"âœ… HKGAI TTSåˆæˆæˆåŠŸ: {audio_file}")
                    return audio_file
                else:
                    logger.warning("âš ï¸  HKGAI TTSåˆæˆå¤±è´¥ï¼Œfallbackåˆ°Edge TTS")
        
        # ä½¿ç”¨Edge TTSï¼ˆä½œä¸ºä¸»è¦å¼•æ“æˆ–fallbackï¼‰
        try:
            logger.info("ğŸ¤ ä½¿ç”¨Edge TTSåˆæˆè¯­éŸ³...")
            tts = self._get_tts()
            if not tts or not tts.is_available():
                logger.warning("âš ï¸  Edge TTSæœåŠ¡ä¸å¯ç”¨")
                return None
            
            # ç¡®å®šè¯­è¨€æ˜ å°„
            tts_language_map = {
                "en": "en",
                "zh": "zh-CN",  # æ™®é€šè¯
                "yue": "zh-HK",  # ç²¤è¯­
                "zh-CN": "zh-CN",
                "zh-HK": "zh-HK",
            }
            tts_lang = tts_language_map.get(language, "zh-CN")
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            import tempfile
            import os
            with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as tmp_audio:
                audio_path = tmp_audio.name
            
            audio_file = tts.speak(
                text=text,
                language=tts_lang,
                output_file=audio_path
            )
            
            if audio_file and os.path.exists(audio_file):
                logger.info(f"âœ… Edge TTSåˆæˆæˆåŠŸ: {audio_file} ({len(text)}å­—ç¬¦)")
                return audio_file
            else:
                return None
                
        except Exception as e:
            logger.warning(f"âŒ è¯­éŸ³åˆæˆå¤±è´¥: {e}")
            return None


# å…¨å±€è¯­éŸ³æœåŠ¡å®ä¾‹
_voice_service = None


def get_voice_service() -> VoiceService:
    """è·å–è¯­éŸ³æœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _voice_service
    
    if _voice_service is None:
        _voice_service = VoiceService()
    
    return _voice_service

