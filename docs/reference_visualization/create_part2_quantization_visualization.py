"""
Part 2: é‡åŒ–æŠ€æœ¯å¯è§†åŒ–è„šæœ¬
ç”Ÿæˆé‡åŒ–å®éªŒçš„ç»¼åˆåˆ†æå›¾è¡¨
"""

import json
import os
import sys
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from datetime import datetime

# è«å…°è¿ªé…è‰²æ–¹æ¡ˆ
MORANDI_COLORS = {
    'dusty_blue': '#9db4c0',      # ç°è“è‰²
    'sage_green': '#a8b5a0',      # é¼ å°¾è‰ç»¿
    'warm_beige': '#c4b5a0',      # æš–ç±³è‰²
    'soft_coral': '#d4a5a5',      # æŸ”å’ŒçŠç‘šè‰²
    'muted_purple': '#b5a7c4',    # æŸ”å’Œç´«è‰²
    'background': '#f7f6f3',      # ç±³ç™½è‰²èƒŒæ™¯
    'dark_text': '#5a5a5a',       # æ·±ç°æ–‡å­—
    'medium_text': '#8a8a8a',     # ä¸­ç°æ–‡å­—
}

# è®¾ç½®è«å…°è¿ªç»˜å›¾æ ·å¼
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.facecolor'] = MORANDI_COLORS['background']
plt.rcParams['axes.facecolor'] = (1.0, 1.0, 1.0, 0.85)  # ç™½è‰²å¸¦85%ä¸é€æ˜åº¦
plt.rcParams['font.size'] = 11
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['axes.spines.top'] = False
plt.rcParams['axes.spines.right'] = False
plt.rcParams['axes.spines.left'] = True
plt.rcParams['axes.spines.bottom'] = True
plt.rcParams['axes.linewidth'] = 1.2
plt.rcParams['text.color'] = MORANDI_COLORS['dark_text']
plt.rcParams['axes.labelcolor'] = MORANDI_COLORS['medium_text']
plt.rcParams['xtick.color'] = MORANDI_COLORS['medium_text']
plt.rcParams['ytick.color'] = MORANDI_COLORS['medium_text']

def print_with_timestamp(message):
    """æ‰“å°å¸¦æ—¶é—´æˆ³çš„æ¶ˆæ¯"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] {message}")
    sys.stdout.flush()

def load_data(file_path="results/part2/all_quantization_results.json"):
    """åŠ è½½Part 2æ•°æ®"""
    if not os.path.exists(file_path):
        print_with_timestamp(f"âŒ æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        return None
    
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def create_comprehensive_visualization():
    """åˆ›å»ºPart 2ç»¼åˆå¯è§†åŒ–"""
    print_with_timestamp("ğŸ¨ ç”ŸæˆPart 2é‡åŒ–æŠ€æœ¯å¯è§†åŒ–...")
    
    data = load_data()
    if not data:
        return None
    
    # ä½¿ç”¨è«å…°è¿ªé…è‰²æ–¹æ¡ˆ
    colors = {
        'primary': MORANDI_COLORS['dusty_blue'],      # ç°è“è‰²
        'secondary': MORANDI_COLORS['muted_purple'],  # æŸ”å’Œç´«è‰²
        'tertiary': MORANDI_COLORS['sage_green'],     # é¼ å°¾è‰ç»¿
        'accent': MORANDI_COLORS['warm_beige'],       # æš–ç±³è‰²
        'danger': MORANDI_COLORS['soft_coral']        # æŸ”å’ŒçŠç‘šè‰²
    }
    
    # åˆ›å»ºå›¾è¡¨
    fig = plt.figure(figsize=(18, 12))
    gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)
    
    fig.suptitle('Part 2: Quantization Techniques - Comprehensive Analysis\nWide-ResNet-28-10 on CIFAR-100', 
                 fontsize=16, fontweight='bold', y=0.96)
    
    baseline_acc = data['baseline']['test_accuracy'] * 100
    baseline_size_mb = data['baseline']['model_path']  # Will calculate from file
    baseline_size_mb = 139.8  # From metadata
    
    # ========== 1. PTQ Methods Comparison ==========
    ax1 = fig.add_subplot(gs[0, 0])
    
    ptq_methods = ['Baseline', 'INT8', 'Dynamic', 'Float16']
    ptq_accs = [
        baseline_acc,
        data['ptq']['int8']['test_accuracy'] * 100,
        data['ptq']['dynamic_range']['test_accuracy'] * 100,
        data['ptq']['float16']['test_accuracy'] * 100
    ]
    ptq_colors = [colors['danger'], colors['primary'], colors['secondary'], colors['tertiary']]
    
    bars = ax1.bar(ptq_methods, ptq_accs, color=ptq_colors, alpha=0.8, edgecolor='black', linewidth=1.5)
    ax1.set_title('PTQ Methods - Accuracy', fontsize=12, fontweight='bold')
    ax1.set_ylabel('Accuracy (%)', fontsize=11)
    ax1.set_ylim(78, 81)
    ax1.grid(True, alpha=0.3)
    
    for bar, acc in zip(bars, ptq_accs):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2, height + 0.05,
                f'{acc:.2f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)
    
    # ========== 2. Model Size Comparison (Log Scale) ==========
    ax2 = fig.add_subplot(gs[0, 1])
    
    size_methods = ['Baseline', 'INT8', 'Dynamic', 'Float16']
    sizes_mb = [
        baseline_size_mb,
        data['ptq']['int8']['model_size_bytes'] / (1024**2),
        data['ptq']['dynamic_range']['model_size_bytes'] / (1024**2),
        data['ptq']['float16']['model_size_bytes'] / (1024**2)
    ]
    
    bars = ax2.bar(size_methods, sizes_mb, color=ptq_colors, alpha=0.8, edgecolor='black', linewidth=1.5)
    ax2.set_title('Model Size Comparison', fontsize=12, fontweight='bold')
    ax2.set_ylabel('Model Size (MB, Log Scale)', fontsize=11)
    ax2.set_yscale('log')
    ax2.grid(True, alpha=0.3)
    
    for bar, size in zip(bars, sizes_mb):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2, height * 1.05,
                f'{size:.1f}MB', ha='center', va='bottom', fontweight='bold', fontsize=9)
    
    # ========== 3. Compression Ratio ==========
    ax3 = fig.add_subplot(gs[0, 2])
    
    compression_methods = ['INT8', 'Dynamic', 'Float16']
    compression_ratios = [
        data['ptq']['int8']['compression_ratio'],
        data['ptq']['dynamic_range']['compression_ratio'],
        data['ptq']['float16']['compression_ratio']
    ]
    comp_colors = [colors['primary'], colors['secondary'], colors['tertiary']]
    
    bars = ax3.bar(compression_methods, compression_ratios, color=comp_colors, alpha=0.8, 
                   edgecolor='black', linewidth=1.5)
    ax3.set_title('Compression Ratio', fontsize=12, fontweight='bold')
    ax3.set_ylabel('Compression Ratio (Ã—)', fontsize=11)
    ax3.set_ylim(0, 14)
    ax3.grid(True, alpha=0.3)
    
    for bar, ratio in zip(bars, compression_ratios):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2, height + 0.3,
                f'{ratio:.1f}Ã—', ha='center', va='bottom', fontweight='bold', fontsize=10)
    
    # ========== 4. Accuracy vs Compression Trade-off ==========
    ax4 = fig.add_subplot(gs[1, 0])
    
    all_methods = ['Baseline', 'Float16', 'Dynamic', 'INT8', 'INT4']
    all_comp_ratios = [1.0, 6.0, 11.95, 11.92, 8.0]
    all_accuracies = [
        baseline_acc,
        data['ptq']['float16']['test_accuracy'] * 100,
        data['ptq']['dynamic_range']['test_accuracy'] * 100,
        data['ptq']['int8']['test_accuracy'] * 100,
        data['extreme']['int4']['test_accuracy'] * 100
    ]
    
    scatter = ax4.scatter(all_comp_ratios, all_accuracies, s=200, alpha=0.7, 
                         c=[colors['danger'], colors['tertiary'], colors['secondary'], 
                            colors['primary'], colors['accent']], edgecolors='black', linewidths=2)
    
    # æ ¹æ®ä½ç½®è°ƒæ•´æ¯ä¸ªæ ‡ç­¾é¿å…é‡å 
    # Dynamic (11.95, 79.59) å’Œ INT8 (11.92, 79.52) ä½ç½®éå¸¸æ¥è¿‘
    label_positions = [
        (-50, 5),    # Baseline (å·¦ä¸Šæ–¹)
        (5, -18),    # Float16 (å³ä¸‹æ–¹)
        (5, 10),     # Dynamic (å³ä¸Šæ–¹)
        (5, -20),    # INT8 (å³ä¸‹æ–¹ï¼Œä¸Dynamicåˆ†å¼€)
        (5, 5)       # INT4 (å³ä¸Šæ–¹)
    ]
    
    for i, method in enumerate(all_methods):
        ax4.annotate(method, (all_comp_ratios[i], all_accuracies[i]), 
                    xytext=label_positions[i], textcoords='offset points', 
                    fontweight='bold', fontsize=9,
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))
    
    ax4.set_title('Accuracy vs Compression Trade-off', fontsize=12, fontweight='bold')
    ax4.set_xlabel('Compression Ratio (Ã—)', fontsize=11)
    ax4.set_ylabel('Accuracy (%)', fontsize=11)
    ax4.set_xlim(0, 13)
    ax4.set_ylim(70, 81)
    ax4.grid(True, alpha=0.3)
    
    # ========== 5. Quantization Types Comparison ==========
    ax5 = fig.add_subplot(gs[1, 1])
    
    x = np.arange(4)
    width = 0.35
    
    methods_compare = ['PTQ\nINT8', 'PTQ\nDynamic', 'PTQ\nFloat16', 'QAT']
    acc_values = [
        data['ptq']['int8']['test_accuracy'] * 100,
        data['ptq']['dynamic_range']['test_accuracy'] * 100,
        data['ptq']['float16']['test_accuracy'] * 100,
        data['qat']['qat']['keras_test_accuracy'] * 100
    ]
    comp_values = [
        data['ptq']['int8']['compression_ratio'],
        data['ptq']['dynamic_range']['compression_ratio'],
        data['ptq']['float16']['compression_ratio'],
        11.92  # Assumed similar to INT8
    ]
    
    bars1 = ax5.bar(x - width/2, acc_values, width, label='Accuracy (%)', 
                    color=colors['primary'], alpha=0.8, edgecolor='black', linewidth=1.5)
    bars2 = ax5.bar(x + width/2, comp_values, width, label='Compression (Ã—)', 
                    color=colors['accent'], alpha=0.8, edgecolor='black', linewidth=1.5)
    
    ax5.set_title('Quantization Methods Comparison', fontsize=12, fontweight='bold')
    ax5.set_ylabel('Value', fontsize=11)
    ax5.set_xticks(x)
    ax5.set_xticklabels(methods_compare)
    ax5.legend()
    ax5.grid(True, alpha=0.3, axis='y')
    
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax5.text(bar.get_x() + bar.get_width()/2, height + 0.5,
                    f'{height:.1f}', ha='center', va='bottom', fontsize=8)
    
    # ========== 6. Accuracy Loss Comparison ==========
    ax6 = fig.add_subplot(gs[1, 2])
    
    loss_methods = ['Float16', 'Dynamic', 'INT8', 'QAT', 'INT4', 'Binary']
    acc_losses = [
        baseline_acc - data['ptq']['float16']['test_accuracy'] * 100,
        baseline_acc - data['ptq']['dynamic_range']['test_accuracy'] * 100,
        baseline_acc - data['ptq']['int8']['test_accuracy'] * 100,
        baseline_acc - data['qat']['qat']['keras_test_accuracy'] * 100,
        baseline_acc - data['extreme']['int4']['test_accuracy'] * 100,
        baseline_acc - data['extreme']['binary']['test_accuracy'] * 100
    ]
    
    colors_loss = [colors['tertiary'], colors['secondary'], colors['primary'], 
                   colors['accent'], colors['accent'], colors['danger']]
    
    bars = ax6.barh(loss_methods, acc_losses, color=colors_loss, alpha=0.8, 
                    edgecolor='black', linewidth=1.5)
    ax6.set_title('Accuracy Loss from Baseline', fontsize=12, fontweight='bold')
    ax6.set_xlabel('Accuracy Loss (%)', fontsize=11)
    ax6.grid(True, alpha=0.3, axis='x')
    ax6.invert_yaxis()
    ax6.set_xlim(0, 80)
    
    for bar, loss in zip(bars, acc_losses):
        width = bar.get_width()
        ax6.text(width + 1, bar.get_y() + bar.get_height()/2,
                f'{loss:.2f}%', ha='left', va='center', fontweight='bold', fontsize=9)
    
    # ä¿å­˜å›¾è¡¨
    output_path = 'results/visualizations/part2_quantization_comprehensive.png'
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print_with_timestamp(f"âœ… Part 2å¯è§†åŒ–å·²ä¿å­˜: {output_path}")
    plt.close()
    
    return output_path

def main():
    """ä¸»å‡½æ•°"""
    print_with_timestamp("ğŸ¨ ç”ŸæˆPart 2é‡åŒ–æŠ€æœ¯å¯è§†åŒ–...")
    print_with_timestamp("=" * 60)
    
    try:
        chart = create_comprehensive_visualization()
        
        if chart:
            print_with_timestamp("\nğŸ‰ Part 2å¯è§†åŒ–ç”Ÿæˆå®Œæˆ!")
            print_with_timestamp(f"ğŸ“Š å›¾è¡¨è·¯å¾„: {chart}")
            print_with_timestamp("\nğŸ’¡ å…³é”®å‘ç°:")
            print_with_timestamp("  â€¢ PTQ INT8æœ€ä¼˜ï¼š11.92Ã—å‹ç¼©ï¼Œä»…-0.09%å‡†ç¡®ç‡æŸå¤±")
            print_with_timestamp("  â€¢ Dynamic Rangeé‡åŒ–æ•ˆæœç›¸å½“ï¼š11.95Ã—å‹ç¼©ï¼Œ-0.02%æŸå¤±")
            print_with_timestamp("  â€¢ Float16ä¿å®ˆæ–¹æ¡ˆï¼š6Ã—å‹ç¼©ï¼Œå‡ ä¹æ— æŸ")
            print_with_timestamp("  â€¢ INT4æé™é‡åŒ–ï¼š8Ã—å‹ç¼©ï¼Œ-7.2%å‡†ç¡®ç‡æŸå¤±")
            print_with_timestamp("  â€¢ Binaryé‡åŒ–å¤±è´¥ï¼šå‡†ç¡®ç‡é™è‡³1.06%")
        
    except Exception as e:
        print_with_timestamp(f"âŒ ç”Ÿæˆå›¾è¡¨æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

