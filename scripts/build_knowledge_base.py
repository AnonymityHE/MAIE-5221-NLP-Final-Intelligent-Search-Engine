"""
å¿«é€Ÿæ„å»ºRAGçŸ¥è¯†åº“
è‡ªåŠ¨ç´¢å¼•é¡¹ç›®æ–‡æ¡£ã€READMEã€é…ç½®æ–‡ä»¶ç­‰
"""
import sys
import os
from pathlib import Path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../')))

from services.storage.file_indexer import FileIndexer
from services.storage.file_storage import file_storage
from services.vector.milvus_client import milvus_client
from services.core.logger import logger
import json

# å®šä¹‰è¦ç´¢å¼•çš„æ–‡æ¡£è·¯å¾„
KNOWLEDGE_SOURCES = {
    "é¡¹ç›®æ–‡æ¡£": [
        "docs/PROJECT_INFO.md",
        "docs/TROUBLESHOOTING.md",
        "docs/WORKFLOW_ARCHITECTURE.md",
        "docs/RAG_RESEARCH_FINDINGS.md",
        "docs/RAG_IMPROVEMENT_PLAN.md",
    ],
    "æ ¹ç›®å½•æ–‡æ¡£": [
        "README.md",
    ],
    "é…ç½®æ–‡æ¡£": [
        "services/config.example.py",
        "services/core/config.example.py",
    ],
}

# FAQæ•°æ®ï¼ˆå†…ç½®ï¼‰
FAQ_DATA = [
    {
        "question": "å¦‚ä½•ä½¿ç”¨ç²¤è¯­è¯­éŸ³è¾“å…¥ï¼Ÿ",
        "answer": """ç³»ç»Ÿæ”¯æŒç²¤è¯­STTï¼ˆè¯­éŸ³è½¬æ–‡å­—ï¼‰ï¼Œé€šè¿‡ä»¥ä¸‹æ–¹å¼ï¼š
1. Whisperæ¨¡å‹ï¼šæ”¯æŒå¤šè¯­è¨€è¯†åˆ«ï¼ŒåŒ…æ‹¬ç²¤è¯­
2. ä¸“ç”¨ç²¤è¯­Speech APIï¼šæä¾›æ›´é«˜å‡†ç¡®åº¦çš„ç²¤è¯­è¯†åˆ«
3. è‡ªåŠ¨è¯­è¨€æ£€æµ‹ï¼šç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«è¾“å…¥è¯­è¨€å¹¶é€‰æ‹©æœ€ä½³è¯†åˆ«å¼•æ“
4. é™çº§æœºåˆ¶ï¼šå¦‚æœä¸“ç”¨APIå¤±è´¥ï¼Œä¼šè‡ªåŠ¨å›é€€åˆ°Whisper

ä½¿ç”¨æ–¹æ³•ï¼šç›´æ¥å¯¹ç€éº¦å…‹é£è¯´ç²¤è¯­ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†ã€‚""",
        "language": "zh",
        "category": "è¯­éŸ³è¾“å…¥",
        "tags": ["speech", "cantonese", "stt", "ç²¤è¯­"]
    },
    {
        "question": "ç³»ç»Ÿæ”¯æŒå“ªäº›è¯­è¨€ï¼Ÿ",
        "answer": """ç³»ç»Ÿæ”¯æŒå¤šè¯­è¨€ï¼ŒåŒ…æ‹¬ï¼š
- ç²¤è¯­ (Cantonese)
- æ™®é€šè¯ (Mandarin Chinese)
- è‹±è¯­ (English)

å¤šè¯­è¨€æ”¯æŒä½“ç°åœ¨ï¼š
1. è¯­éŸ³è¾“å…¥ï¼šSTTæ”¯æŒä¸‰è¯­
2. æ–‡æœ¬æŸ¥è¯¢ï¼šembeddingæ¨¡å‹æ”¯æŒå¤šè¯­è¨€
3. è¯­éŸ³è¾“å‡ºï¼šTTSæ”¯æŒå¤šè¯­è¨€
4. çŸ¥è¯†åº“ï¼šå¯ç´¢å¼•å’Œæ£€ç´¢å¤šè¯­è¨€æ–‡æ¡£""",
        "language": "zh",
        "category": "ç³»ç»ŸåŠŸèƒ½",
        "tags": ["multilingual", "languages", "å¤šè¯­è¨€"]
    },
    {
        "question": "How to query stock prices?",
        "answer": """To query stock prices, you can use natural language queries like:
- "What is the current price of Apple stock?"
- "Show me NVIDIA stock price"
- "Compare Tesla and BYD stock prices"

The system uses:
1. Finance tool with real-time data APIs
2. Intelligent entity extraction (company names â†’ ticker symbols)
3. Multi-source data aggregation (Yahoo Finance, CoinGecko for crypto)

The finance tool supports both US stocks (AAPL, MSFT, etc.) and Hong Kong/China stocks (0700.HK for Tencent, BABA for Alibaba).""",
        "language": "en",
        "category": "Tools",
        "tags": ["finance", "stocks", "query"]
    },
    {
        "question": "ç³»ç»Ÿçš„å·¥ä½œæµæ˜¯ä»€ä¹ˆï¼Ÿ",
        "answer": """ç³»ç»Ÿé‡‡ç”¨æ™ºèƒ½å·¥ä½œæµæ¶æ„ï¼š

**LLMé©±åŠ¨çš„å·¥ä½œæµï¼ˆä¸»è¦ï¼‰**ï¼š
1. LLMåˆ†æç”¨æˆ·æŸ¥è¯¢
2. ç”Ÿæˆå¤šæ­¥éª¤æ‰§è¡Œè®¡åˆ’ï¼ˆJSONæ ¼å¼ï¼‰
3. åŠ¨æ€æ‰§è¡Œå¼•æ“æŒ‰æ­¥éª¤è°ƒç”¨å·¥å…·
4. ç»¼åˆç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

**è§„åˆ™é©±åŠ¨çš„å·¥ä½œæµï¼ˆå¤‡é€‰ï¼‰**ï¼š
1. åŸºäºå…³é”®è¯æ£€æµ‹æŸ¥è¯¢ç±»å‹
2. åº”ç”¨é¢„å®šä¹‰å·¥ä½œæµæ¨¡æ¿
3. æŒ‰å›ºå®šæ­¥éª¤æ‰§è¡Œ

**å•å·¥å…·è°ƒç”¨ï¼ˆç®€å•æŸ¥è¯¢ï¼‰**ï¼š
- ç›´æ¥è°ƒç”¨æœ€ç›¸å…³çš„å•ä¸ªå·¥å…·

ä¼˜å…ˆçº§ï¼šLLMå·¥ä½œæµ > è§„åˆ™å·¥ä½œæµ > å•å·¥å…·

æ”¯æŒçš„å·¥å…·ï¼š
- local_rag: æœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢
- web_search: ç½‘é¡µæœç´¢
- finance: é‡‘èæ•°æ®æŸ¥è¯¢
- weather: å¤©æ°”æŸ¥è¯¢
- transport: äº¤é€šä¿¡æ¯æŸ¥è¯¢""",
        "language": "zh",
        "category": "æ¶æ„",
        "tags": ["workflow", "architecture", "å·¥ä½œæµ"]
    },
    {
        "question": "What is the difference between HKGAI and Gemini APIs?",
        "answer": """The system supports multiple LLM providers:

**HKGAI API (Primary)**:
- Default provider for LLM requests
- Stable and reliable
- Used for workflow planning and answer generation

**Gemini API (Fallback)**:
- Backup provider
- Activated when HKGAI fails or exceeds quota
- Supports multiple models (gemini-2.0-flash-exp, gemini-1.5-pro)
- Includes usage monitoring

**Intelligent Fallback**:
- System tracks HKGAI failure count
- Automatically switches to Gemini after 3 consecutive failures
- Resets counter when HKGAI recovers
- Ensures high availability

You can explicitly choose a provider:
```python
result = unified_llm_client.chat(
    system_prompt="...",
    user_prompt="...",
    provider="gemini"  # or "hkgai"
)
```""",
        "language": "en",
        "category": "LLM",
        "tags": ["llm", "api", "hkgai", "gemini", "fallback"]
    },
    {
        "question": "å¦‚ä½•æ·»åŠ æ–°æ–‡æ¡£åˆ°çŸ¥è¯†åº“ï¼Ÿ",
        "answer": """æœ‰å¤šç§æ–¹å¼æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“ï¼š

**æ–¹æ³•1ï¼šä½¿ç”¨æ–‡ä»¶ä¸Šä¼ API**
```bash
curl -X POST http://localhost:8000/api/upload \
  -F "file=@/path/to/document.pdf"
```

**æ–¹æ³•2ï¼šä½¿ç”¨å‘½ä»¤è¡Œè„šæœ¬**
```bash
python scripts/index_documents.py --file document.pdf
python scripts/index_documents.py --dir documents/ --recursive
```

**æ–¹æ³•3ï¼šé€šè¿‡å­˜å‚¨ç›®å½•**
å°†æ–‡ä»¶æ”¾å…¥ `storage/uploads/` ç›®å½•ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ç´¢å¼•

**æ”¯æŒçš„æ–‡ä»¶æ ¼å¼**ï¼š
- PDF (.pdf)
- Wordæ–‡æ¡£ (.docx)
- Markdown (.md)
- æ–‡æœ¬æ–‡ä»¶ (.txt)
- ä»£ç æ–‡ä»¶ (.py, .js, .javaç­‰)
- JSON (.json)
- CSV (.csv)

**å¤„ç†æµç¨‹**ï¼š
1. æ–‡ä»¶è§£æå’Œæ–‡æœ¬æå–
2. æ™ºèƒ½åˆ†å—ï¼ˆchunkingï¼‰
3. ç”Ÿæˆembeddingå‘é‡
4. å­˜å‚¨åˆ°Milvuså‘é‡æ•°æ®åº“
5. åˆ›å»ºå…ƒæ•°æ®ç´¢å¼•""",
        "language": "zh",
        "category": "çŸ¥è¯†åº“ç®¡ç†",
        "tags": ["knowledge_base", "indexing", "documents", "ä¸Šä¼ "]
    },
    {
        "question": "What is reranking and why is it important?",
        "answer": """Reranking is a crucial component in RAG systems:

**What is Reranking?**
After initial retrieval (e.g., vector similarity search), reranking re-orders the results using a more sophisticated model to improve relevance.

**Why Important?**
1. **Better Relevance**: Initial retrieval may miss nuances; reranker captures deeper semantic relationships
2. **Reduced Noise**: Filters out less relevant results even if they have high vector similarity
3. **Context Aware**: Considers query-document interaction, not just isolated embeddings

**Our Implementation**:
- Model: `cross-encoder/ms-marco-MiniLM-L-6-v2`
- Features:
  * Semantic similarity scoring
  * Credibility weighting
  * Freshness factor (newer docs ranked higher)
  * Configurable weights for each factor

**Two-Stage Process**:
1. Stage 1: Fast vector retrieval (get top 50)
2. Stage 2: Reranking with cross-encoder (refine to top 10)

This balances speed and accuracy.""",
        "language": "en",
        "category": "RAG Techniques",
        "tags": ["reranking", "retrieval", "rag", "accuracy"]
    },
]

def create_faq_documents():
    """å°†FAQæ•°æ®è½¬æ¢ä¸ºå¯ç´¢å¼•çš„æ–‡æ¡£"""
    faq_docs = []
    for i, faq in enumerate(FAQ_DATA):
        doc_content = f"""# FAQ: {faq['question']}

**é—®é¢˜**: {faq['question']}

**ç­”æ¡ˆ**: 
{faq['answer']}

**åˆ†ç±»**: {faq['category']}
**è¯­è¨€**: {faq['language']}
**æ ‡ç­¾**: {', '.join(faq['tags'])}
"""
        faq_docs.append({
            "content": doc_content,
            "metadata": {
                "doc_id": f"faq_{i+1}",
                "doc_title": faq['question'],
                "doc_type": "faq",
                "language": faq['language'],
                "category": faq['category'],
                "tags": faq['tags'],
                "source": "builtin_faq",
            }
        })
    return faq_docs

def build_knowledge_base():
    """æ„å»ºå®Œæ•´çš„çŸ¥è¯†åº“"""
    logger.info("\n" + "="*100)
    logger.info("ğŸ—ï¸  å¼€å§‹æ„å»ºRAGçŸ¥è¯†åº“".center(100))
    logger.info("="*100 + "\n")
    
    total_indexed = 0
    total_failed = 0
    
    # åˆå§‹åŒ–ç´¢å¼•å™¨
    file_indexer = FileIndexer()
    
    # 1. ç´¢å¼•é¡¹ç›®æ–‡æ¡£
    logger.info("ğŸ“š ç¬¬1æ­¥ï¼šç´¢å¼•é¡¹ç›®æ–‡æ¡£")
    logger.info("-" * 100)
    
    for category, file_list in KNOWLEDGE_SOURCES.items():
        logger.info(f"\nğŸ”– åˆ†ç±»: {category}")
        for file_path in file_list:
            full_path = Path(file_path)
            if not full_path.exists():
                logger.warning(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}")
                total_failed += 1
                continue
            
            try:
                logger.info(f"   ğŸ“„ æ­£åœ¨ç´¢å¼•: {file_path}")
                
                # ä¸Šä¼ æ–‡ä»¶åˆ°file_storage
                with open(full_path, 'rb') as f:
                    file_content = f.read()
                
                # ä¿å­˜æ–‡ä»¶
                result_info = file_storage.save_file(
                    file_content=file_content,
                    filename=full_path.name,
                    mime_type='text/plain'  # ç®€åŒ–ï¼Œå®é™…å¯æ ¹æ®æ‰©å±•ååˆ¤æ–­
                )
                file_id = result_info['file_id']
                
                # è°ƒç”¨æ–‡ä»¶ç´¢å¼•å™¨
                result = file_indexer.index_file(file_id)
                if result.get('success'):
                    chunks_indexed = result.get('chunks_indexed', 0)
                    total_indexed += chunks_indexed
                    logger.info(f"   âœ… æˆåŠŸç´¢å¼• {chunks_indexed} ä¸ªå—")
                else:
                    logger.error(f"   âŒ ç´¢å¼•å¤±è´¥: {result.get('message')}")
                    total_failed += 1
            except Exception as e:
                logger.error(f"   âŒ ç´¢å¼•å¼‚å¸¸: {e}")
                import traceback
                traceback.print_exc()
                total_failed += 1
    
    # 2. ç´¢å¼•FAQæ•°æ®
    logger.info("\n" + "-" * 100)
    logger.info("ğŸ’¬ ç¬¬2æ­¥ï¼šç´¢å¼•FAQæ•°æ®")
    logger.info("-" * 100)
    
    faq_docs = create_faq_documents()
    logger.info(f"   å‡†å¤‡ç´¢å¼• {len(faq_docs)} ä¸ªFAQæ¡ç›®")
    
    for i, faq_doc in enumerate(faq_docs):
        try:
            # å°†FAQå†…å®¹å†™å…¥ä¸´æ—¶æ–‡ä»¶å†ç´¢å¼•
            temp_faq_path = Path(f"data/temp_faq_{i}.md")
            temp_faq_path.parent.mkdir(exist_ok=True)
            
            with open(temp_faq_path, 'w', encoding='utf-8') as f:
                f.write(faq_doc['content'])
            
            # ä¿å­˜æ–‡ä»¶
            result_info = file_storage.save_file(
                file_content=faq_doc['content'].encode('utf-8'),
                filename=f"faq_{i+1}_{faq_doc['metadata']['language']}.md",
                mime_type='text/markdown'
            )
            file_id = result_info['file_id']
            
            # ç´¢å¼•
            result = file_indexer.index_file(file_id)
            if result.get('success'):
                chunks_indexed = result.get('chunks_indexed', 0)
                total_indexed += chunks_indexed
                logger.info(f"   âœ… FAQç´¢å¼•æˆåŠŸ: {faq_doc['metadata']['doc_title'][:50]}...")
            else:
                logger.error(f"   âŒ FAQç´¢å¼•å¤±è´¥: {result.get('message')}")
                total_failed += 1
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_faq_path.exists():
                temp_faq_path.unlink()
                
        except Exception as e:
            logger.error(f"   âŒ FAQç´¢å¼•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            total_failed += 1
    
    # 3. è·å–æœ€ç»ˆç»Ÿè®¡
    logger.info("\n" + "="*100)
    logger.info("ğŸ“Š çŸ¥è¯†åº“æ„å»ºå®Œæˆ".center(100))
    logger.info("="*100)
    
    try:
        stats = milvus_client.get_collection_stats()
        logger.info(f"\nçŸ¥è¯†åº“ç»Ÿè®¡:")
        logger.info(f"  - æ€»æ–‡æ¡£æ•°: {stats.get('total_docs', 0)}")
        logger.info(f"  - æ€»å—æ•°: {stats.get('total_chunks', 0)}")
        logger.info(f"  - æœ¬æ¬¡ç´¢å¼•æˆåŠŸ: {total_indexed} ä¸ªå—")
        logger.info(f"  - ç´¢å¼•å¤±è´¥: {total_failed} é¡¹")
        
        doc_types = stats.get('doc_types', {})
        if doc_types:
            logger.info(f"\næ–‡æ¡£ç±»å‹åˆ†å¸ƒ:")
            for doc_type, count in doc_types.items():
                logger.info(f"  - {doc_type}: {count}")
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
    
    logger.info("\n" + "="*100)
    logger.info("âœ… çŸ¥è¯†åº“æ„å»ºæµç¨‹å®Œæˆï¼")
    logger.info("="*100 + "\n")
    
    # æµ‹è¯•æ£€ç´¢
    logger.info("ğŸ§ª æ‰§è¡Œæµ‹è¯•æ£€ç´¢...")
    logger.info("-" * 100)
    
    test_queries = [
        "å¦‚ä½•ä½¿ç”¨ç²¤è¯­è¾“å…¥ï¼Ÿ",
        "What tools are available?",
        "ç³»ç»Ÿæ¶æ„æ˜¯ä»€ä¹ˆï¼Ÿ"
    ]
    
    for query in test_queries:
        logger.info(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {query}")
        try:
            from services.vector.retriever import retriever
            results = retriever.search(query, top_k=3)
            logger.info(f"   âœ… æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
            for i, result in enumerate(results[:2], 1):
                logger.info(f"   {i}. [{result.get('score', 0):.3f}] {result.get('content', '')[:80]}...")
        except Exception as e:
            logger.error(f"   âŒ æ£€ç´¢å¤±è´¥: {e}")
    
    logger.info("\n" + "="*100)
    logger.info("ğŸ‰ å…¨éƒ¨å®Œæˆï¼çŸ¥è¯†åº“å·²å°±ç»ªï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨äº†ã€‚")
    logger.info("="*100 + "\n")

if __name__ == "__main__":
    build_knowledge_base()

